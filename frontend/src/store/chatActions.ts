import { Edge, Node } from 'reactflow';
import { API_BASE_URL } from '../constants';
import { ChatMessage, FlowNodeData, L7Status, LoadingState, ProcessContext } from '../types';
import { validateL7Label } from '../utils/l7Rules';
import { buildConversationSummary, buildRecentTurns, serialize } from './helpers';

type AddMessage = (message: ChatMessage) => void;

interface StoreSlice {
  processContext: ProcessContext | null;
  nodes: Node<FlowNodeData>[];
  edges: Edge[];
  messages: ChatMessage[];
  dividerYs: number[];
  loadingState: LoadingState;
  addMessage: AddMessage;
}

type StoreSet = (partial: Partial<StoreSlice> | ((state: StoreSlice) => Partial<StoreSlice>)) => void;
type StoreGet = () => StoreSlice & { setLoadingMessage: (message: string) => void };

interface ChatActionDeps {
  generateId: (prefix?: string) => string;
  debugTrace: (event: string, payload?: Record<string, unknown>) => void;
  extractBotText: (data: unknown) => string;
  friendlyTag: (ruleId: string) => string;
}

const PLACEHOLDER_LABELS = new Set(['ìƒˆ íƒœìŠ¤í¬', 'ìƒˆ ë‹¨ê³„', 'ë¶„ê¸° ì¡°ê±´?', 'íŒë‹¨ ì¡°ê±´', 'L6 í”„ë¡œì„¸ìŠ¤', 'í•˜ìœ„ ì ˆì°¨']);

export function createChatActions(set: StoreSet, get: StoreGet, deps: ChatActionDeps) {
  const { generateId, debugTrace, extractBotText, friendlyTag } = deps;

  return {
    validateNode: async (id: string) => {
      const { nodes } = get();
      const node = nodes.find((n) => n.id === id);
      if (!node || ['start', 'end', 'subprocess'].includes(node.data.nodeType)) return null;
      if (PLACEHOLDER_LABELS.has((node.data.label || '').trim())) {
        set({
          nodes: get().nodes.map((n) =>
            n.id === id ? { ...n, data: { ...n.data, l7Status: 'none' as L7Status } } : n,
          ),
        });
        return null;
      }

      set({
        nodes: get().nodes.map((n) =>
          n.id === id ? { ...n, data: { ...n.data, l7Status: 'checking' as L7Status } } : n,
        ),
      });

      try {
        debugTrace('validateNode:start', { id, label: node.data.label, type: node.data.nodeType });
        const hasSwimLane = get().dividerYs.length > 0;
        const data = validateL7Label(node.data.label || '', node.data.nodeType, hasSwimLane);
        debugTrace('validateNode:success', {
          id,
          pass: !!data.pass,
          score: data.score ?? null,
          issues: (data.issues || []).length,
        });

        set({
          nodes: get().nodes.map((n) =>
            n.id === id
              ? {
                  ...n,
                  data: {
                    ...n.data,
                    l7Status: (
                      data.pass
                        ? data.issues?.some((issue: any) => issue.severity === 'warning')
                          ? 'warning'
                          : 'pass'
                        : 'reject'
                    ) as L7Status,
                    l7Score: data.score ?? 0,
                    l7Issues: (data.issues || []).map((issue: any) => ({
                      ...issue,
                      friendlyTag: issue.friendlyTag || friendlyTag(issue.ruleId),
                    })),
                    l7Rewrite: data.rewriteSuggestion || undefined,
                  },
                }
              : n,
          ),
        });
        return data;
      } catch {
        debugTrace('validateNode:error', { id });
        set({
          nodes: get().nodes.map((n) =>
            n.id === id ? { ...n, data: { ...n.data, l7Status: 'none' as L7Status } } : n,
          ),
        });
        return null;
      }
    },

    sendChat: async (msg: string) => {
      const { processContext: ctx, nodes, edges, addMessage, loadingState } = get();
      addMessage({ id: generateId('msg'), role: 'user', text: msg, timestamp: Date.now() });
      let newCount = (loadingState.requestCount || 0) + 1;
      set({
        loadingState: {
          active: true,
          message: 'ì‘ë‹µ ìƒì„± ì¤‘...',
          startTime: Date.now(),
          elapsed: 0,
          requestCount: newCount,
        },
      });

      try {
        debugTrace('chat:start', { messageLength: msg.length, nodeCount: nodes.length, edgeCount: edges.length });
        const { nodes: serializedNodes, edges: serializedEdges } = serialize(nodes, edges);
        const recentTurns = buildRecentTurns(get().messages);
        const conversationSummary = buildConversationSummary(get().messages);
        const response = await fetch(`${API_BASE_URL}/chat`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            message: msg,
            context: ctx || {},
            currentNodes: serializedNodes,
            currentEdges: serializedEdges,
            recentTurns,
            conversationSummary,
          }),
        });

        if (!response.ok) {
          const errorText = await response.text().catch(() => '');
          throw new Error(`HTTP ${response.status} ${response.statusText} ${errorText.slice(0, 300)}`);
        }

        const data = await response.json();
        const validSuggestions = (data.suggestions || []).filter(
          (suggestion: any) =>
            suggestion.summary?.trim() || suggestion.newLabel?.trim() || suggestion.labelSuggestion?.trim(),
        );
        debugTrace('chat:success', {
          hasText: !!(data.message || data.speech || data.guidance),
          suggestions: validSuggestions.length,
          quickQueries: (data.quickQueries || []).length,
        });

        addMessage({
          id: generateId('msg'),
          role: 'bot',
          text: extractBotText(data),
          suggestions: validSuggestions.map((suggestion: any) => ({ action: suggestion.action || 'ADD', ...suggestion })),
          quickQueries: data.quickQueries || [],
          timestamp: Date.now(),
        });
      } catch {
        debugTrace('chat:error');
        addMessage({
          id: generateId('msg'),
          role: 'bot',
          timestamp: Date.now(),
          text: 'âš ï¸ AI ì„œë²„ì™€ ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\n\në¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìžì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.',
          quickQueries: ['ë‹¤ì‹œ ì‹œë„'],
        });
      } finally {
        const currentLoading = get().loadingState;
        newCount = Math.max(0, (currentLoading.requestCount || 1) - 1);
        set({ loadingState: { ...currentLoading, active: newCount > 0, requestCount: newCount } });
      }
    },

    requestReview: async () => {
      const { processContext: ctx, nodes, edges, addMessage, loadingState } = get();
      let newCount = (loadingState.requestCount || 0) + 1;
      set({
        loadingState: {
          active: true,
          message: 'í”Œë¡œìš° ë¶„ì„ ì¤‘...',
          startTime: Date.now(),
          elapsed: 0,
          requestCount: newCount,
        },
      });
      addMessage({ id: generateId('msg'), role: 'user', text: 'ðŸ” ì „ì²´ íë¦„ ê²€í†  ìš”ì²­', timestamp: Date.now() });

      try {
        debugTrace('review:start', { nodeCount: nodes.length, edgeCount: edges.length });
        const { nodes: serializedNodes, edges: serializedEdges } = serialize(nodes, edges);
        const response = await fetch(`${API_BASE_URL}/review`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            currentNodes: serializedNodes,
            currentEdges: serializedEdges,
            userMessage: 'í”„ë¡œì„¸ìŠ¤ ë¶„ì„ + ì œì•ˆ',
            context: ctx || {},
          }),
        });

        if (!response.ok) {
          const errorText = await response.text().catch(() => '');
          throw new Error(`HTTP ${response.status} ${response.statusText} ${errorText.slice(0, 300)}`);
        }

        const data = await response.json();
        const validSuggestions = (data.suggestions || []).filter(
          (suggestion: any) =>
            suggestion.summary?.trim() || suggestion.newLabel?.trim() || suggestion.labelSuggestion?.trim(),
        );
        debugTrace('review:success', {
          hasText: !!(data.speech || data.message),
          suggestions: validSuggestions.length,
          quickQueries: (data.quickQueries || []).length,
        });

        addMessage({
          id: generateId('msg'),
          role: 'bot',
          text: extractBotText(data) || 'ë¦¬ë·° ì™„ë£Œ',
          suggestions: validSuggestions.map((suggestion: any) => ({ action: suggestion.action || 'ADD', ...suggestion })),
          quickQueries: data.quickQueries || [],
          timestamp: Date.now(),
        });
      } catch {
        debugTrace('review:error');
        addMessage({
          id: generateId('msg'),
          role: 'bot',
          timestamp: Date.now(),
          text: 'âš ï¸ AI ì„œë²„ì™€ ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\n\në¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìžì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.',
          quickQueries: ['ðŸ” í”Œë¡œìš° ë¶„ì„ ë‹¤ì‹œ ì‹œë„'],
        });
      } finally {
        const currentLoading = get().loadingState;
        newCount = Math.max(0, (currentLoading.requestCount || 1) - 1);
        set({ loadingState: { ...currentLoading, active: newCount > 0, requestCount: newCount } });
      }
    },
  };
}
